# 强化学习智能体适应性与泛化能力研究框架

## 1. 项目概述

本项目是一个功能强大且高度可扩展的Python实验框架，旨在系统性地研究强化学习（RL）智能体在动态变化的环境中的**适应性（Adaptability）**与**泛化能力（Generalization）**。

它能够全自动地执行从模型训练、超参数优化（HPO）、多场景适应性测试到最终结果可视化分析的全过程。框架的核心是评估一个在“初始环境”中训练好的智能体，在被迁移到一系列具有不同“环境复杂度”的“目标环境”时的表现，并根据其性能决定是否触发适应性训练（微调或重训练）。

## 2. 核心功能

*   **⚡️ 全自动实验流**：只需在开始时进行一次性配置（交互式或命令行），即可自动完成所有实验，无需人工干预。
*   **🧠 多算法支持**：内置支持多种主流强化学习算法，如 `PPO`, `A2C`, `DQN` 等，并可轻松扩展。
*   **⚙️ 动态环境生成**：支持从多种概率分布（如正态、泊松、伽马、Beta等）动态生成具有不同**复杂度**的环境，模拟多样化的挑战。
*   **📈 智能适应策略**：模型在遇到新环境时，会首先评估其“第一反应”（泛化能力）。只有当性能低于预设阈值时，才会自动触发适应性训练（微调或重训练）。
*   **🚀 集成超参数优化(HPO)**：内置 [Optuna](https://optuna.org/) 支持，可为指定的算法和场景自动寻找最优超参数，并与默认参数进行性能对比。
*   **📊 出版级可视化**：自动生成一系列精心设计、信息密度极高的图表，用于深度分析和结果展示，所有图表均为SCI期刊风格。
*   **🖥️ 双模式运行**：
    *   **交互模式**：通过引导式问答轻松配置实验。
    *   **非交互模式**：通过命令行参数直接运行，方便进行批量实验和服务器部署。

## 3. 项目结构

```
.
├── main_experiment.py      # 主程序入口，负责驱动整个实验流程
├── config.py               # 核心配置文件，定义算法、环境、超参数等
├── plotting_utils.py       # 绘图工具库，包含所有高级可视化函数的实现
├── training_utils.py       # 训练和评估工具库，封装了模型训练和评估的逻辑
├── environment.py          # 自定义Gym环境(MultiDistributionEnv)的实现
├── hpo_definitions.py      # 超参数优化(HPO)的相关定义和执行逻辑
├── utils.py                # 通用工具函数，如文件处理、交互选择等
├── requirements.txt        # 项目依赖
└── plots/                  # 所有生成的图表默认输出目录
```

## 4. 安装与运行

### 4.1. 安装

1.  **克隆或下载项目**
2.  **创建虚拟环境 (推荐)**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```
3.  **安装依赖**
    ```bash
    pip install -r requirements.txt
    ```
    *注意：如果遇到字体警告，请确保您的系统中安装了 `Microsoft YaHei` (微软雅黑) 字体，或在 `plotting_utils.py` 中修改 `DEFAULT_FONT`为你系统中的可用中文字体。*

### 4.2. 运行实验

#### 交互模式 (推荐首次使用)

直接运行主文件，程序会通过问答形式引导您完成所有配置。

```bash
python main_experiment.py
```

您将依次选择：
1.  要测试的算法 (可多选)
2.  用于初始训练的源环境 (可多选)
3.  用于适应性测试的目标环境 (可多选)
4.  是否运行HPO对比
5.  希望生成的图表 (可多选)
6.  图表输出格式 (PNG/SVG)

#### 非交互模式 (用于脚本化和批量运行)

通过命令行参数直接指定所有配置，实现全自动运行。

**参数说明:**
*   `--non-interactive`: 激活非交互模式
*   `--algos`: 算法列表 (e.g., `PPO A2C`)
*   `--initial-dists`: 初始训练环境名称列表 (需与`config.py`中的`name`完全匹配)
*   `--target-dists`: 目标适应环境名称列表
*   `--run-hpo`: 运行HPO对比 (可选)
*   `--plots`: 要生成的图表ID列表 (见`main_experiment.py`中的`define_plot_options`函数)
*   `--plot-format`: 图表格式 (`png`或`svg`, 默认为`png`)

**示例:**
```bash
python main_experiment.py --non-interactive \
  --algos PPO \
  --initial-dists "正态分布(标准,μ10,σ2)" \
  --target-dists "正态-大幅均值改变(μ14,σ2)" "拉普拉斯分布(窄,μ10,b1)" \
  --run-hpo \
  --plots dumbbell_plot complexity_synthesis hpo_profile_radar \
  --plot-format svg
```

## 5. 关键图表解读

项目会自动生成一系列图表，以下是其中最具代表性的几张：

### 5.1. 复杂度 vs. 适应性表现综合图
*   **文件名**: `cmplx_vs_adapt_perf_*.svg`
*   **用途**: **项目的核心图表**。它将模型的泛化能力、适应过程和理想性能三大信息整合到一张图中。
*   **解读**:
    *   **箭头**的起点(●)是“适应前”性能，终点(○)是“适应后”性能。绿色箭头代表性能提升，红色代表下降。
    *   **星形(☆)** 代表在该环境下从零训练的“理想性能”。
    *   通过对比**箭头终点**和**星形**的差距，可以判断适应策略的有效性。

### 5.2. 适应性表现哑铃图
*   **文件名**: `adaptation_dumbbell_*.svg`
*   **用途**: 直观对比模型从一个初始环境迁移到**多个不同目标环境**后的性能变化。
*   **解读**:
    *   每一行是一个适应任务。红点是适应前，绿点是适应后。
    *   中间的连线清晰地标注了**具体的性能变化值** (+/-)。
    *   整个图表按性能提升幅度排序，让您能一眼找到效果最好和最差的适应场景。

### 5.3. 综合性能雷达图
*   **文件名**: `radar_perf_profile_*.svg`
*   **用途**: 从多个维度（如最终奖励、奖励提升、稳定性、训练效率等）综合评估和对比不同算法或参数配置的优劣。
*   **解读**:
    *   **彩色粗实线**代表HPO优化后的性能。
    *   **灰色细虚线**代表默认参数的性能。
    *   雷达图的“覆盖面积”越大，说明该配置的综合性能越强。

## 6. 如何扩展

### 添加新的环境分布
1.  打开 `config.py` 文件。
2.  在 `ALL_DISTRIBUTION_CONFIGS` 列表中，仿照现有格式添加一个新的字典。
3.  **必须**包含 `name` (唯一标识), `dist_type` (需与`environment.py`中支持的类型匹配), 和 `params` (该分布所需的参数)。
4.  可选地，您可以在 `environment.py` 的 `DIST_GENERATORS` 字典中添加全新的分布类型和对应的 `lambda` 采样函数。

### 添加新的算法
1.  在 `config.py` 中，将新算法的名称添加到 `ALL_AVAILABLE_ALGORITHMS` 列表。
2.  在 `ALGO_CLASS_MAP` 字典中，添加算法名称到其 `stable-baselines3` 类的映射。
3.  在 `DEFAULT_HYPERPARAMS` 中为新算法提供一套默认超参数。
4.  （可选）若要支持HPO，需在 `hpo_definitions.py` 的 `define_search_space` 函数中为其定义超参数的搜索范围。