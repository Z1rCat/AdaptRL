# 强化学习智能体适应性分析框架

**版本: 1.0.0**
<!-- README-KEEPALIVE-COMMENT-001 -->
## 目录
1. [项目概述](#1-项目概述-overview)
2. [核心问题](#2-核心问题-core-problem)
3. [主要特性](#3-主要特性-key-features)
4. [项目结构](#4-项目结构-project-structure)
5. [安装指南](#5-安装指南-installation)
6. [使用方法](#6-使用方法-usage)
7. [实验输出详解](#7-实验输出详解-experiment-output)
8. [核心概念与方法论](#8-核心概念与方法论-core-concepts--methodology)
9. [未来可扩展方向](#9-未来可扩展方向-future-work)

---
<!-- README-KEEPALIVE-COMMENT-002 -->
## 1. 项目概述 (Overview)

本项目是一个功能完备、高度自动化的强化学习（RL）实验框架，旨在深入研究和评估RL智能体（Agent）在环境动态发生变化时的**适应能力**。

框架核心是让智能体学习一个独特的决策任务，并通过改变任务的内在概率分布来模拟环境变化。它系统地评估了多种主流RL算法（如PPO, A2C, DQN）在从一个已知环境迁移到一个新环境时的表现，并提供了从“从零重训练”（Retraining）和“增量微调”（Fine-tuning）两种适应策略。

整个实验流程被设计为**“一次性配置，全自动运行”**，集成了强大的**超参数优化（HPO）**、详细的日志记录和丰富的多维度数据可视化功能，为研究RL的泛化与适应性问题提供了一个强大的工具。

## 2. 核心问题 (Core Problem)

传统的RL研究通常假设环境是静态的（Stationary）。然而，现实世界中的许多应用场景的环境是动态变化的。本项目旨在回答以下核心问题：
*   当环境的关键特征发生变化时，一个已经训练好的RL智能体表现如何？
*   “从零开始重训练”和“在原有模型上微调”哪种适应策略更优？
*   不同的RL算法在适应性上是否存在差异？
*   环境变化的“难度”（我们称之为**复杂度**）如何影响智能体的适应性能？
*   我们能否通过自动化超参数搜索，找到一组能提升模型适应能力的“最优”参数？

为了研究这些问题，我们设计了一个核心任务：智能体需要判断一个从**隐藏的概率分布**中抽取的随机数，是大于还是小于一个固定的阈值（`current_fixed_value = 10.0`）。通过在实验中切换不同的概率分布（例如，从一个窄正态分布切换到一个宽均匀分布），我们有效地模拟了环境的动态变化。
<!-- README-KEEPALIVE-COMMENT-003 -->
## 3. 主要特性 (Key Features)

*   **模块化设计**：项目代码结构清晰，将环境定义、训练/评估逻辑、绘图工具、超参数优化和配置文件分离，易于理解和扩展。

*   **全自动实验流**：通过 `main_experiment.py`，用户只需在程序启动时通过交互式菜单完成所有配置（选择算法、分布、是否进行HPO、要生成的图表），后续所有实验将自动执行，无需人工干预。

*   **集成超参数优化 (HPO)**：
    *   使用业界领先的 `Optuna` 库进行高效的超参数搜索。
    *   优化目标函数 (`_objective_base`) 专门为**适应性任务**设计，综合了模型在初始环境和目标环境上的表现，旨在找到泛化和适应能力强的参数组合。
    *   支持中位数剪枝（Median Pruner），可自动提前终止性能不佳的试验，大幅提升优化效率。

*   **丰富的多维度数据可视化 (`plotting_utils.py`)**：
    *   **学习曲线**：展示训练过程中奖励和正确率的变化，支持双Y轴显示。
    *   **性能对比图**：通过箱线图、柱状图等形式，直观对比模型在适应前后的性能差异。
    *   **高级性能雷达图**：从6个关键维度（初始/适应阶段的奖励与耗时、总体奖励与耗时）全面剖析默认参数与HPO优化后参数的综合表现，并以数值标注，极具洞察力。
    *   **复杂度 vs. 性能分析**：通过散点图探索环境的量化复杂度与智能体最终性能之间的关系。
    *   所有图表均支持**中文字体**显示，并自动保存到 `plots/` 目录。

*   **量化的分布复杂度**：
    *   项目独创性地提出了一个衡量分布区分难度的指标：`Complexity = P_smaller / P_larger`，其中 `P_smaller = min(P(X <= threshold), P(X > threshold))`。
    *   该指标值域为 [0, 1]，越接近1表示随机数落在阈值两侧的概率越接近，任务越难，越考验智能体的决策能力。

*   **灵活的配置 (`config.py`)**：
    *   所有实验参数（如训练步数、算法、分布配置等）均在 `config.py` 中集中管理。
    *   用户可以非常方便地添加新的算法、定义新的概率分布或调整默认超参数。
<!-- README-KEEPALIVE-COMMENT-004 -->
## 4. 项目结构 (Project Structure)

项目遵循模块化的设计原则，将不同的功能逻辑分离到独立的文件中，便于维护和扩展。

| 文件 / 目录          | 主要职责 / 内容                                              |
| :------------------- | :----------------------------------------------------------- |
| **`核心逻辑`**       |                                                              |
| `main_experiment.py` | **项目主入口**。负责用户交互、调度整个实验流程、并调用其他模块。 |
| `config.py`          | **核心配置文件 (重要)**。集中管理所有实验参数、算法超参、分布定义和全局常量。 |
| `environment.py`     | 定义了 `MultiDistributionEnv`，即智能体交互的核心Gym环境。     |
| `training_utils.py`  | 封装了模型**训练** (`train_agent`) 和**评估** (`evaluate_agent`) 的核心逻辑。 |
| `hpo_definitions.py` | 定义了使用 `Optuna` 进行**超参数优化 (HPO)** 的相关函数和搜索空间。 |
| **`辅助工具与配置`** |                                                              |
| `plotting_utils.py`  | 包含了所有用于**数据可视化**的绘图函数，例如雷达图、学习曲线等。 |
| `utils.py`           | 提供通用辅助函数，如中文字体配置、文件名清理、复杂度计算等。 |
| `requirements.txt`   | 列出了项目运行所需的全部Python库及其版本。                   |
| **`自动生成目录`**   |                                                              |
| `logs/`              | (自动生成) 存放控制台输出日志和详细的逐回合Excel训练数据。   |
| `plots/`             | (自动生成) 存放所有生成的图表和最终的 `.csv` 结果汇总文件。  |
| `hpo_studies/`       | (自动生成) 存放 `Optuna` 的 `.db` 数据库文件，记录HPO过程和结果。 |
## 5. 安装指南 (Installation)

1.  **克隆或下载项目**
    将本项目代码下载到您的本地机器。
<!-- README-KEEPALIVE-COMMENT-005 -->
2.  **创建虚拟环境 (强烈推荐)**
    为了避免包版本冲突，强烈建议您使用虚拟环境。
    >
    > **使用 Python 内置的 venv:**
    >
    > `python -m venv venv`
    >
    > **激活环境:**
    >
    > *   On macOS/Linux: `source venv/bin/activate`
    > *   On Windows: `venv\Scripts\activate`

3.  **安装依赖**
    项目的所有依赖项都在 `requirements.txt` 文件中。使用pip进行安装：
    > `pip install -r requirements.txt`

4.  **中文字体说明**
    本项目在绘图时需要中文字体支持。`utils.py` 中的 `set_chinese_font_for_matplotlib` 函数会尝试自动查找并设置系统中的可用中文字体。如果您的图表出现中文乱码（显示为方块），请确保您的操作系统已安装至少一种中文字体。

## 6. 使用方法 (Usage)

直接在您的终端中运行主实验脚本即可启动程序：
> `python main_experiment.py`

程序启动后，会进入一个交互式的命令行配置流程。以下是一个示例：

**1. 选择算法**：您可以选择一个或多个要测试的算法。输入数字，多个用逗号隔开，或输入`all`。
>
> 请选择 要运行的算法 (输入数字，多个用逗号隔开，或输入 'all' 选择全部):
> >   1. PPO
> >   2. A2C
> >   3. DQN
>
> 输入您的选择 (或输入 'q' 退出选择): `1,2`
<!-- README-KEEPALIVE-COMMENT-006 -->
**2. 选择初始训练分布**：选择一个或多个智能体初始训练时所处的环境。

**3. 选择目标适应场景**：选择一个或多个智能体需要适应的新环境。

**4. 决定是否运行HPO**：输入`yes`或`no`来决定是否为选定的算法组合运行超参数优化。
>
> 是否为选定算法运行HPO并与默认参数对比? (yes/no, 默认no): `yes`

**5. 选择要生成的图表**：您可以选择在实验结束后自动生成哪些分析图表。

完成以上配置后，整个实验将**全自动运行**，并将所有输出保存在对应的目录中。您可以在控制台看到实时的进度输出。

## 7. 实验输出详解 (Experiment Output)

实验结束后，您将在项目根目录下发现几个新生成的文件夹：

*   **`logs/`**:
    *   `main_run_log_{timestamp}.txt`: 包含了本次运行所有控制台输出的完整日志。
    *   `{algo}_{...}_episode_log.xlsx`: 记录了每个训练阶段详细的逐回合数据（奖励、正确率、步数等）。

*   **`plots/`**:
    *   `ALL_RESULTS_SUMMARY_{timestamp}.csv`: **最重要的输出文件之一**。它是一个包含了所有实验配置和最终结果的摘要CSV文件，是进行最终分析的核心数据源。
    *   各种 `.png` 图表文件，根据您在启动时选择的绘图选项生成。

*   **`hpo_studies/`**:
    *   `.db` 文件：Optuna的SQLite数据库文件。如果运行了HPO，这里会记录下每一次尝试的参数和结果。
    *   `best_{...}_params.csv`: HPO找到的最优参数会保存在这个CSV文件中。
<!-- README-KEEPALIVE-COMMENT-007 -->
## 8. 核心概念与方法论 (Core Concepts & Methodology)

*   **适应策略 (Adaptation Strategy)**：
    1.  **评估 (Evaluate)**：当模型从初始环境切换到目标环境后，首先会进行一次评估，得到“适应前性能”。
    2.  **决策 (Decide)**：将“适应前性能”的平均奖励与初始环境基线性能的一个折扣值（`threshold_ratio`）进行比较。
    3.  **执行 (Execute)**：
        *   若性能**低于**阈值，则认为模型无法直接适应，触发**重训练 (Retraining)**。
        *   若性能**高于或等于**阈值，则认为模型具备一定泛化能力，触发**微调 (Fine-tuning)**。

*   **微调 (Fine-tuning)**：加载已训练好的模型，将其学习率动态调整为一个更小的值（`FINETUNE_LEARNING_RATE`），然后在新的目标环境上进行短暂的、增量式的训练。

*   **HPO目标函数 (HPO Objective Function)**：为了找到适应性强的超参数，HPO的目标函数被定义为 **(初始环境的平均奖励 + 适应后环境的平均奖励) / 2**。这个设计旨在平衡模型在原始任务上的稳定性和在新任务上的快速适应能力。

## 9. 未来可扩展方向 (Future Work)

*   **增加更多算法**：可以在 `config.py` 和 `hpo_definitions.py` 中轻松添加对新算法的支持（如SAC等）。
*   **设计更复杂的环境**：`environment.py` 可以被扩展，例如引入更复杂的观察空间或动态变化的阈值。
*   **探索新的适应策略**：可以实现更高级的适应方法，例如基于不确定性估计的自适应学习率、或者利用旧环境经验的策略重用算法。
*   **构建Web分析仪表盘**：可以使用 `Streamlit` 或 `Dash` 等工具，将 `plots/` 中的结果CSV文件转化为一个交互式的Web应用，方便地筛选和查看实验结果。
<!-- README-KEEPALIVE-COMMENT-008 -->